---
title: "Preprocessing and on"
output: html_document
date: '2022-06-06'
---

```{r}
#calling library
library(caret)
library(tidyverse)
library(shiny)
library(readr)
library(ggplot2)
library(tidyr)
library(interactions)
library(dplyr)
library(skimr)
```



```{r }
library(readr)
new_survey_dataset <- read_csv("new_survey_dataset2.csv")

head(new_survey_dataset)

```



```{r }
# Create the training and test datasets
set.seed(100)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(new_survey_dataset$treatment_seek, p=0.8, list=FALSE)

# Step 2: Create the training  dataset
trainData <- new_survey_dataset[trainRowNumbers,]

# Step 3: Create the test dataset
testData <- new_survey_dataset[-trainRowNumbers,]

# Store X and Y for later use.
x = trainData[, 7:27]
y = trainData$treatment_seek 


```





```{r}
# Quick display of two cabapilities of GGally, to assess the distribution and correlation of variables 
library(GGally)
 
# Create data 
x$treatment_seek <- as.numeric(x$treatment_seek)
 
# Check correlations (as scatterplots), distribution and print corrleation coefficient 
ggcorr(x, method = c("everything", "pearson")) 

```

```{r}

# Set the seed for reproducibility
set.seed(100)

new_survey_dataset$treatment_seek <- as.factor(new_survey_dataset$treatment_seek)

# Train the model using randomForest and predict on the training data itself.
model_mars = train(treatment_seek ~ ., data=new_survey_dataset, method='rpart')
model_mars


```

```{r}
library(dplyr)
library(data.table)
library(datasets)
library(ggplot2)

pcain <- copy(x)
pcain$treatment_seek<- NULL
pcain$self_employed <- as.numeric(pcain$self_employed)
 
pca <- prcomp(pcain, scale. = TRUE, center = TRUE)
x <- as.data.frame(pca$x)
```
 
```{r}
install.packages("ggbilot")
library(ggbiplot)

ggbiplot( pca)
```





```{r}

x$treatment_seek <- as.factor(y)

model_mars = train(treatment_seek ~ ., data=x, method='rf')
model_mars
```


```{r}
AUC = list()
Accuracy = list()
```

```{r}
#Trainging using Logistic Regression alogorithm
logistic <- glm(x$treatment_seek ~ ., data=x, family = 'binomial')
summary(logistic)

## Now calculate the overall "Pseudo R-squared" and its p-value
ll.null <- logistic$null.deviance/-2
ll.proposed <- logistic$deviance/-2
 
## McFadden's Pseudo R^2 = [ LL(Null) - LL(Proposed) ] / LL(Null)
(ll.null - ll.proposed) / ll.null

## The p-value for the R^2
1 - pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))

#Graph
predicted.data <- data.frame(
  probability.of.ts=logistic$fitted.values,
  ts=x$treatment_seek)
 
predicted.data <- predicted.data[
  order(predicted.data$probability.of.ts, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)
 

ggplot(data=predicted.data, aes(x=rank, y=probability.of.ts)) +
  geom_point(aes(color=ts), alpha=1, shape=4, stroke=2) +
  xlab("Index") +
  ylab("Predicted probability of treatment seek")

#ts = treatment_seek
```


```{r}
#Modeling using decision tree
library("party")
data.ctree<-ctree(x$treatment_seek ~ ., data=x)
table(predict(data.ctree), x$treatment_seek)
plot(data.ctree)

```



